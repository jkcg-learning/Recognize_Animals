{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recognize_Animals.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOQynxT1VmcYsFB+KZrv7nS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkcg-learning/Recognize_Animals/blob/master/Recognize_Animals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HbSU96M0_ei",
        "colab_type": "text"
      },
      "source": [
        "# **Dphi**\n",
        "\n",
        "**Deep Learning Bootcamp - Assignment 2 - Intermediate: Recognize Animals**\n",
        "\n",
        "**Submitted by :** ***Jyothish Kumar C G***\n",
        "\n",
        "Image recognition is a vital component in robotics such as driverless vehicles or domestic robots. Image recognition is also important in image search engines such as Google or Bing image search whereby you use rich image content to query for similar stuff. Like in Google photos where the system uses image recognition to categorize your images into things like cats, dogs, people and so on so that you can quickly search your albums for things like, “give me photos of my cat”, that's awesome.\n",
        "\n",
        "\n",
        "\n",
        "Ever noticed how Facebook instantly recognises your friend’s face and asks you if you want to tag him in that photo? That’s image recognition. That’s just a basic example.\n",
        "\n",
        "**Objective**\n",
        "\n",
        "You are working on a robotics project where you are required to train your robot so that it can differentiate between 5 animals or birds. Your task here is to build a deep learning model that helps you recognize the animal or bird in images.\n",
        "\n",
        "\n",
        "**About the Data**\n",
        "\n",
        "The training dataset consists of about 9k medium quality animal images belonging to 5 categories: butterfly, sheep, cow, squirrel, elephant. - mucca (cow), pecora (sheep), elefante (elephant), farfalla (butterfly) and scoiattolo (squirrel). All the images have been collected from \"google images\" and have been checked by human. There is some erroneous data to simulate real conditions (eg. images taken by users of your app).\n",
        "\n",
        "***Dataset Link:***https://drive.google.com/file/d/176E-pLhoxTgWsJ3MeoJQV_GXczIA6g8D/view?usp=sharing\n",
        "\n",
        "From the above link you will be able to download a zip file named ‘animal_dataset_intermediate.zip’. After you extract this zip file, you will get three files:\n",
        "\n",
        "**train** - contains five folders each folder containing images around 1000 to 2000 of those 5 five animals.  Each image has a unique name.\n",
        "\n",
        "**test** - contains 910 random images of those 5 animals whose predictions you are to submit on DPhi platform.\n",
        "\n",
        "**Testing_set_animals.csv** - this is the order of the predictions for each image that is to be submitted on the platform. Make sure the predictions you download are with their image’s filename in the same order as given in this file.\n",
        " \n",
        "\n",
        "**Evaluation Criteria**\n",
        "\n",
        "Submissions are evaluated using Accuracy Score.\n",
        "\n",
        " \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5UCTaqkWWOI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "567a8496-074b-4af5-efe8-7667fc4e0424"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import TensorBoard,EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq1ux5p9WPpg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "759aa0be-5142-4d1f-b322-7059dde5d7db"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xTL9eHbSWRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='176E-pLhoxTgWsJ3MeoJQV_GXczIA6g8D', \n",
        "                                    dest_path='./data/animal_dataset_intermediate.zip', unzip=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh4wfbNaS12p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d518083b-9417-46f4-ca05-db04b47f6c0b"
      },
      "source": [
        "import os\n",
        "DATA_PATH = './data/animal_dataset_intermediate/train/'\n",
        "print('Cleaning Folder Names')\n",
        "for i in os.listdir(DATA_PATH):\n",
        "  os.renames(DATA_PATH+i,DATA_PATH+i.split('_')[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning Folder Names\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAQgun29ikYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing necessary libraries\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "class_names = ['elefante','farfalla','mucca','pecora','scoiattolo']\n",
        "IMG_SIZE = 256"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71d3HI0xmuiD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "3916aa3d-bae5-4c88-8ea7-a6f0ce3373fa"
      },
      "source": [
        "import pandas as pd\n",
        "test_data = pd.read_csv('./data/animal_dataset_intermediate/Testing_set_animals.csv')\n",
        "test_data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>e030b20928e90021d85a5854ee454296eb70e3c818b413...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e030b20929e90021d85a5854ee454296eb70e3c818b413...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e030b2092be90021d85a5854ee454296eb70e3c818b413...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>e030b2092ce90021d85a5854ee454296eb70e3c818b413...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e030b2092de90021d85a5854ee454296eb70e3c818b413...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>OIP-5ual0F5ZPZRdkGcj8uSH0AHaFj.jpeg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>906</th>\n",
              "      <td>OIP-5VwIBS0B8SxZbUiAHBJg7gHaE8.jpeg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>907</th>\n",
              "      <td>OIP-5WG0rHWAZYtu0utoZfuaAgHaFj.jpeg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>908</th>\n",
              "      <td>OIP-5ZwfeYunG6CT2wEI7OjybQHaEo.jpeg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>909</th>\n",
              "      <td>OIP-6A6SpPbz_YUI4ElMo-UhuQHaE8.jpeg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>910 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              filename  target\n",
              "0    e030b20928e90021d85a5854ee454296eb70e3c818b413...     NaN\n",
              "1    e030b20929e90021d85a5854ee454296eb70e3c818b413...     NaN\n",
              "2    e030b2092be90021d85a5854ee454296eb70e3c818b413...     NaN\n",
              "3    e030b2092ce90021d85a5854ee454296eb70e3c818b413...     NaN\n",
              "4    e030b2092de90021d85a5854ee454296eb70e3c818b413...     NaN\n",
              "..                                                 ...     ...\n",
              "905                OIP-5ual0F5ZPZRdkGcj8uSH0AHaFj.jpeg     NaN\n",
              "906                OIP-5VwIBS0B8SxZbUiAHBJg7gHaE8.jpeg     NaN\n",
              "907                OIP-5WG0rHWAZYtu0utoZfuaAgHaFj.jpeg     NaN\n",
              "908                OIP-5ZwfeYunG6CT2wEI7OjybQHaEo.jpeg     NaN\n",
              "909                OIP-6A6SpPbz_YUI4ElMo-UhuQHaE8.jpeg     NaN\n",
              "\n",
              "[910 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dlQ1PjJ5rfx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "f0de25f4-ddf9-4654-e709-ca1ba7fa3afc"
      },
      "source": [
        "test_data['target'] = \"./data/animal_dataset_intermediate/test/\" + test_data['filename']\n",
        "test_data\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>e030b20928e90021d85a5854ee454296eb70e3c818b413...</td>\n",
              "      <td>./data/animal_dataset_intermediate/test/e030b2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e030b20929e90021d85a5854ee454296eb70e3c818b413...</td>\n",
              "      <td>./data/animal_dataset_intermediate/test/e030b2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e030b2092be90021d85a5854ee454296eb70e3c818b413...</td>\n",
              "      <td>./data/animal_dataset_intermediate/test/e030b2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>e030b2092ce90021d85a5854ee454296eb70e3c818b413...</td>\n",
              "      <td>./data/animal_dataset_intermediate/test/e030b2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>e030b2092de90021d85a5854ee454296eb70e3c818b413...</td>\n",
              "      <td>./data/animal_dataset_intermediate/test/e030b2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>OIP-5ual0F5ZPZRdkGcj8uSH0AHaFj.jpeg</td>\n",
              "      <td>./data/animal_dataset_intermediate/test/OIP-5u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>906</th>\n",
              "      <td>OIP-5VwIBS0B8SxZbUiAHBJg7gHaE8.jpeg</td>\n",
              "      <td>./data/animal_dataset_intermediate/test/OIP-5V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>907</th>\n",
              "      <td>OIP-5WG0rHWAZYtu0utoZfuaAgHaFj.jpeg</td>\n",
              "      <td>./data/animal_dataset_intermediate/test/OIP-5W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>908</th>\n",
              "      <td>OIP-5ZwfeYunG6CT2wEI7OjybQHaEo.jpeg</td>\n",
              "      <td>./data/animal_dataset_intermediate/test/OIP-5Z...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>909</th>\n",
              "      <td>OIP-6A6SpPbz_YUI4ElMo-UhuQHaE8.jpeg</td>\n",
              "      <td>./data/animal_dataset_intermediate/test/OIP-6A...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>910 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              filename                                             target\n",
              "0    e030b20928e90021d85a5854ee454296eb70e3c818b413...  ./data/animal_dataset_intermediate/test/e030b2...\n",
              "1    e030b20929e90021d85a5854ee454296eb70e3c818b413...  ./data/animal_dataset_intermediate/test/e030b2...\n",
              "2    e030b2092be90021d85a5854ee454296eb70e3c818b413...  ./data/animal_dataset_intermediate/test/e030b2...\n",
              "3    e030b2092ce90021d85a5854ee454296eb70e3c818b413...  ./data/animal_dataset_intermediate/test/e030b2...\n",
              "4    e030b2092de90021d85a5854ee454296eb70e3c818b413...  ./data/animal_dataset_intermediate/test/e030b2...\n",
              "..                                                 ...                                                ...\n",
              "905                OIP-5ual0F5ZPZRdkGcj8uSH0AHaFj.jpeg  ./data/animal_dataset_intermediate/test/OIP-5u...\n",
              "906                OIP-5VwIBS0B8SxZbUiAHBJg7gHaE8.jpeg  ./data/animal_dataset_intermediate/test/OIP-5V...\n",
              "907                OIP-5WG0rHWAZYtu0utoZfuaAgHaFj.jpeg  ./data/animal_dataset_intermediate/test/OIP-5W...\n",
              "908                OIP-5ZwfeYunG6CT2wEI7OjybQHaEo.jpeg  ./data/animal_dataset_intermediate/test/OIP-5Z...\n",
              "909                OIP-6A6SpPbz_YUI4ElMo-UhuQHaE8.jpeg  ./data/animal_dataset_intermediate/test/OIP-6A...\n",
              "\n",
              "[910 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVFP_kURuHGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = []\n",
        "\n",
        "try:\n",
        "    #files = glob.glob(\"./data/animal_dataset_intermediate/test\"+\"/*\") # get files in each folder(class)\n",
        "    files = test_data['target']\n",
        "    for f in files:\n",
        "      img = cv2.imread(f) #read the image\n",
        "      img = cv2.resize(img,(IMG_SIZE,IMG_SIZE)) #resize the image\n",
        "      data_test.append([np.array(img)]) #Append images and corresponding labels to data\n",
        "except:\n",
        "    pass   \n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VIIrfN7_4eP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86b491fc-2b51-4fec-8cc6-3a96dfbab97e"
      },
      "source": [
        "type(data_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR8gQ8fzAJQz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "70299cdf-21df-4e83-b4f8-98504c586abd"
      },
      "source": [
        "data_test_tf = tf.convert_to_tensor(data_test, np.float32)\n",
        "print(type(data_test_tf))\n",
        "data_test_tf[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 256, 256, 3), dtype=float32, numpy=\n",
              "array([[[[118., 147., 151.],\n",
              "         [119., 148., 152.],\n",
              "         [122., 149., 154.],\n",
              "         ...,\n",
              "         [ 70., 129., 109.],\n",
              "         [ 70., 129., 109.],\n",
              "         [ 69., 128., 108.]],\n",
              "\n",
              "        [[118., 147., 151.],\n",
              "         [120., 149., 153.],\n",
              "         [122., 149., 154.],\n",
              "         ...,\n",
              "         [ 71., 129., 109.],\n",
              "         [ 70., 128., 109.],\n",
              "         [ 69., 127., 108.]],\n",
              "\n",
              "        [[118., 147., 151.],\n",
              "         [119., 148., 152.],\n",
              "         [121., 148., 153.],\n",
              "         ...,\n",
              "         [ 72., 128., 109.],\n",
              "         [ 72., 128., 109.],\n",
              "         [ 71., 125., 108.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 83., 163., 164.],\n",
              "         [ 83., 163., 164.],\n",
              "         [ 82., 162., 163.],\n",
              "         ...,\n",
              "         [ 97., 142., 158.],\n",
              "         [ 95., 142., 156.],\n",
              "         [ 95., 142., 156.]],\n",
              "\n",
              "        [[ 81., 161., 162.],\n",
              "         [ 81., 161., 162.],\n",
              "         [ 80., 160., 161.],\n",
              "         ...,\n",
              "         [ 96., 141., 157.],\n",
              "         [ 94., 141., 155.],\n",
              "         [ 95., 142., 156.]],\n",
              "\n",
              "        [[ 80., 160., 161.],\n",
              "         [ 80., 160., 161.],\n",
              "         [ 80., 160., 161.],\n",
              "         ...,\n",
              "         [ 95., 140., 156.],\n",
              "         [ 94., 141., 155.],\n",
              "         [ 94., 141., 155.]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScS2rQP4Am1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e155e60b-c8a5-4db0-b531-cae7f95db14d"
      },
      "source": [
        "data_test_tf_reshaped = tf.reshape(data_test_tf,[910,256,256,3])\n",
        "data_test_tf_reshaped.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([910, 256, 256, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "194ZEvONyJps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "53a27e20-ca5b-4fad-a06a-9b44bdf5df46"
      },
      "source": [
        "data_test_normalized = np.divide(data_test_tf_reshaped, 255.0)\n",
        "data_test_normalized[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.4627451 , 0.5764706 , 0.5921569 ],\n",
              "        [0.46666667, 0.5803922 , 0.59607846],\n",
              "        [0.47843137, 0.58431375, 0.6039216 ],\n",
              "        ...,\n",
              "        [0.27450982, 0.5058824 , 0.42745098],\n",
              "        [0.27450982, 0.5058824 , 0.42745098],\n",
              "        [0.27058825, 0.5019608 , 0.42352942]],\n",
              "\n",
              "       [[0.4627451 , 0.5764706 , 0.5921569 ],\n",
              "        [0.47058824, 0.58431375, 0.6       ],\n",
              "        [0.47843137, 0.58431375, 0.6039216 ],\n",
              "        ...,\n",
              "        [0.2784314 , 0.5058824 , 0.42745098],\n",
              "        [0.27450982, 0.5019608 , 0.42745098],\n",
              "        [0.27058825, 0.49803922, 0.42352942]],\n",
              "\n",
              "       [[0.4627451 , 0.5764706 , 0.5921569 ],\n",
              "        [0.46666667, 0.5803922 , 0.59607846],\n",
              "        [0.4745098 , 0.5803922 , 0.6       ],\n",
              "        ...,\n",
              "        [0.28235295, 0.5019608 , 0.42745098],\n",
              "        [0.28235295, 0.5019608 , 0.42745098],\n",
              "        [0.2784314 , 0.49019608, 0.42352942]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.3254902 , 0.6392157 , 0.6431373 ],\n",
              "        [0.3254902 , 0.6392157 , 0.6431373 ],\n",
              "        [0.32156864, 0.63529414, 0.6392157 ],\n",
              "        ...,\n",
              "        [0.38039216, 0.5568628 , 0.61960787],\n",
              "        [0.37254903, 0.5568628 , 0.6117647 ],\n",
              "        [0.37254903, 0.5568628 , 0.6117647 ]],\n",
              "\n",
              "       [[0.31764707, 0.6313726 , 0.63529414],\n",
              "        [0.31764707, 0.6313726 , 0.63529414],\n",
              "        [0.3137255 , 0.627451  , 0.6313726 ],\n",
              "        ...,\n",
              "        [0.3764706 , 0.5529412 , 0.6156863 ],\n",
              "        [0.36862746, 0.5529412 , 0.60784316],\n",
              "        [0.37254903, 0.5568628 , 0.6117647 ]],\n",
              "\n",
              "       [[0.3137255 , 0.627451  , 0.6313726 ],\n",
              "        [0.3137255 , 0.627451  , 0.6313726 ],\n",
              "        [0.3137255 , 0.627451  , 0.6313726 ],\n",
              "        ...,\n",
              "        [0.37254903, 0.54901963, 0.6117647 ],\n",
              "        [0.36862746, 0.5529412 , 0.60784316],\n",
              "        [0.36862746, 0.5529412 , 0.60784316]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuSWwiFAT4fD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ecd3711b-06d8-49e4-ffdc-24ccd537b002"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255., # rescaling\n",
        "                                   rotation_range = 40,  # for augmentation\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   validation_split = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale = 1.0/255.,validation_split = 0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\"./data/animal_dataset_intermediate/train\",\n",
        "                                                    batch_size = 32,\n",
        "                                                    subset=\"training\",\n",
        "                                                    class_mode = 'categorical', \n",
        "                                                    target_size = (256, 256))\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\"./data/animal_dataset_intermediate/train\",\n",
        "                                                    batch_size = 32,\n",
        "                                                    subset = \"validation\",\n",
        "                                                    class_mode = 'categorical', \n",
        "                                                    target_size = (256, 256))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6558 images belonging to 5 classes.\n",
            "Found 1638 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-btXmNAXgvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrr= ReduceLROnPlateau(\n",
        "                       monitor='val_loss', #Metric to be measured\n",
        "                       factor=.01, #Factor by which learning rate will be reduced\n",
        "                       patience=3,  #No. of epochs after which if there is no improvement in the val_loss, the learning rate is reduced\n",
        "                       min_lr=1e-5) #The minimum learning rate "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzRlf-ygXh7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_rate=.001\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOdVHHfwxDp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting helper function\n",
        "def plotaccuracy(hist):\n",
        "    plt.plot(hist.history['accuracy'])\n",
        "    plt.plot(hist.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xd0BBNKxHmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plotting helper function\n",
        "def plotloss(hist):\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qela79hZW0Gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "c1781112-a322-48ed-c582-1978c734a6f9"
      },
      "source": [
        "INPUT_SHAPE = (256, 256, 3)\n",
        "\n",
        "# define sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Add the vgg convolutional base model\n",
        "#model.add(vgg_layers)\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(4, 4), strides=(1, 1), \n",
        "                                activation='relu', padding='same', input_shape=INPUT_SHAPE))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "# define conv-pool layers - set 2\n",
        "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), \n",
        "                                activation='relu', padding='same', input_shape=INPUT_SHAPE))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# add flatten layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "\n",
        "# add dense layers with some dropout\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu',kernel_regularizer = 'l2'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu',kernel_regularizer = 'l2'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "#model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "\n",
        "# add output layer\n",
        "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=adam, \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# view model layers\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 256, 256, 32)      1568      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 16)      4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 65536)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               33554944  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 33,727,029\n",
            "Trainable params: 33,726,517\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7yEDfrNW4Cf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "52dde001-c4e1-47ab-e3d6-69025465c0a7"
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, \n",
        "                                               restore_best_weights=True,\n",
        "                                               verbose=2)\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data = val_generator,\n",
        "                    batch_size=16,\n",
        "                    callbacks=[es_callback], \n",
        "                    epochs=EPOCHS,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "205/205 [==============================] - 94s 460ms/step - loss: 5.1548 - accuracy: 0.3422 - val_loss: 2.9961 - val_accuracy: 0.3791\n",
            "Epoch 2/100\n",
            " 93/205 [============>.................] - ETA: 49s - loss: 2.9251 - accuracy: 0.4372"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnFuqC0TxL74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotaccuracy(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLROEIWyxMoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotloss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBCklmmvyGSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict(data_test_normalized)\n",
        "#if using softmax activation on output layer\n",
        "predicted_labels  = np.argmax(preds,axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mCPz8RMyLRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63WyzENKyQBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accessing classnames with predicted clases\n",
        "final_predictions = [class_names[i] for i in predicted_labels]\n",
        "final_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EUS6-AQcuVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define input shape\n",
        "INPUT_SHAPE_VGG = (256, 256, 3)\n",
        "\n",
        "# get the VGG19 model\n",
        "vgg_layers = tf.keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, \n",
        "                                               input_shape=INPUT_SHAPE_VGG)\n",
        "\n",
        "vgg_layers.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzzmjBQfczvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fine-tune all the layers\n",
        "for layer in vgg_layers.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg_layers.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnrv2uhpc4OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define sequential model\n",
        "model_vgg = tf.keras.models.Sequential()\n",
        "\n",
        "# Add the vgg convolutional base model\n",
        "model_vgg.add(vgg_layers)\n",
        "\n",
        "# add flatten layer\n",
        "model_vgg.add(tf.keras.layers.Flatten())\n",
        "\n",
        "\n",
        "model_vgg.add(tf.keras.layers.Dense(512, activation='relu',input_dim=512,kernel_regularizer = 'l2'))\n",
        "model_vgg.add(Dropout(.3))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model_vgg.add(Dense(256,activation=('relu'),kernel_regularizer = 'l1'))\n",
        "model_vgg.add(Dropout(.2))\n",
        "model_vgg.add(Dense(128,activation=('relu')))\n",
        "\n",
        "\n",
        "# add output layer\n",
        "model_vgg.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model_vgg.compile(optimizer=sgd, \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# view model layers\n",
        "model_vgg.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPDi6950dIWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS_VGG = 100\n",
        "\n",
        "es_callback_VGG = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2, \n",
        "                                               restore_best_weights=True,\n",
        "                                               verbose=2)\n",
        "\n",
        "history_VGG = model_vgg.fit(train_generator,\n",
        "                    validation_data = val_generator,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[es_callback_VGG], \n",
        "                    epochs=EPOCHS_VGG,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe9bNAqtxSA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotaccuracy(history_VGG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "038CDYD1xXg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotloss(history_VGG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc2zjICCdHAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_VGG = model_vgg.predict(data_test_normalized)\n",
        "#if using softmax activation on output layer\n",
        "predicted_labels_VGG  = np.argmax(preds_VGG,axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBHEcX-EdOM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_labels_VGG"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7WJ1lRYdH5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accessing classnames with predicted clases\n",
        "final_predictions_VGG = [class_names[i] for i in predicted_labels_VGG]\n",
        "final_predictions_VGG"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}